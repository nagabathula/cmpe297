Transformers and finetuning with LLMs 


a) 
Link for Nanogpt implementation in pytorch Colab:

https://colab.research.google.com/drive/1NFPxz7oewowmfZuDMpWbj1nX-Jp3iWp4?usp=sharing

Link for nanogpt implementation in tensorflow colab:

https://colab.research.google.com/drive/1d9yhrryfLTHFMbEyg-rv-gA6zyXuSHFZ?usp=sharing

Link for nanogpt implementation in JAX colab:

https://colab.research.google.com/drive/1NCcijGHXd8Sb5ggKHfh9xdfD1Ri824fO?usp=sharing


b) Implement "textbooks are all you need" case study with your own data

full colab and all artifacts

Link for Colab:

https://colab.research.google.com/drive/1lXwlkB3Cp-sYWzC8HsS8hZkpILU17VIn?usp=sharing
